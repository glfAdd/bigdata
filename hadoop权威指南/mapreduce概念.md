##### 数据流

- job(作业)

  ```
  job 是 MapReduce 客户端需要执行的一个工作单元, 包括输入数据, MapReduce 程序和配置信息
  ```
  
- task (任务)

  ```
  hadoop 将 job 分成若干个 task 执行, 包括 map 和 reduce 两类任务. 这些任务运行在集群的节点上, 由 yarn 进行调度, 如果一个任务失败, 它将在另一个不同节点上自动重新运行.
  ```

- input split (输入分片/分片)

  ```
  指 hadoop 将 MapReduce 的数据如据划分为等长的小数据块
  hadoop 为每个分片构建一个 map 任务, 该任务执行用户定义的 map 函数来处理分片中的数据
  ```

- 数据本地化优化

  ```
  hadoop 在存储输入数据的节点上执行 map 任务可以获得最佳性能, 因为无需带宽资源
  当 map 任务输入分片所在的所有 HDFS 节点都在运行 map 任务时, 可能会从该数据块所在机架的其他节点上寻早空闲的 槽(slot) 来运行该 map 任务, 这时会有网络传输
  ```

- 分片大小带来的影响

  ```
  1. 如果并行处理每个分片, 切每个分片的数据较小, 整个处理过程会有更好的负载均衡
  2. 如果分片切的太小, 管理分片的时间和构建 map 的时间总和将决定整个执行时间
  3. 一般分片大小与 HDFS 块的大小相同, 默认 128MB. 切片跨越两个数据块, HDFS 可能不会同时保存这两个数据块, 因此切片中的部分数据需要通过网络传输到 map 任务运行的节点上, 这比所有数据在一个节点上执行低
  ```

- map 任务结果保存的地方

  ```
  map 任务输出写入本地磁盘, 不是 HDFS
  map 输出的是中间结果, 由 reduce 处理后才是最终结果
  job 完成后 map 的结果可以删除
  如果 map 中间结果传给reduce 前失败, hadoop 会在另一个节点上重新运行整个 map 任务
  ```

- reduce 任务

  ```
  reduce 任务没有"数据本地化"优势, 因为通常单个 reduce 任务的输入通常来自所有 mapper 的输出, 需要网络传输. 
  数据在 reduce 端合并, 由用户定义的 reduce 函数执行
  reduce 输出写入 HDFS 实现高可用
  ```

- shuffle 混洗

  ```
  指 map 和 reduce 之间的数据流
  每个 reduce 任务的输入来自许多 map
  ```

- combiner 函数

  ```
  是一种优化方案, combiner 的输出作为 reduce 的输入, 减少 mapper 与 reduce 之间数据传输量
  但不是所有函数都具备 combiner 属性, 如求平均指的函数
  
  
  例如: 
  第1个 map 的输出:
  (1950, 0)
  (1950, 10)
  (1950, 20)
  
  第2个 map 的输出:
  (1950, 25)
  (1950, 15)
  ********** 求气温最大值 **********
  1. 不使用 combiner 函数, reduce 函数调用时输入如下:
  reduce(1950, [0, 10, 20, 25, 15])
  最大指输入结果 (1950, 25)
  
  2. 使用 combiner 函数, 找出每个 map 输出的最大值, reduce 函数调用时输入如下:
  reduce(1950, [20, 25])
  最大指输入结果 (1950, 25)
  
  max(0, 10, 20, 25, 15) = max(max(0, 10, 20), max(25, 15)) = max(20, 25) = 25
  ********** 求气温平均值 **********
  1. 不使用 combiner 函数
  mean(0, 10, 20, 25, 15) = 15
  
  2. 使用 combiner 函数
  mean(mean(0, 10, 20), mean(25, 15)) = mean(10, 20) = 15
  ```

  



## todo

```
map 什么时候将结果传给 reduce?
map 上的任务什么时候排序?
map 和 reduce 分别是如何指定的









```

